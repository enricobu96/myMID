{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "import pickle\n",
    "\n",
    "from environment import Environment, Scene, Node, derivative_of\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "desired_max_time = 100\n",
    "pred_indices = [2, 3]\n",
    "state_dim = 6\n",
    "frame_diff = 10\n",
    "desired_frame_diff = 1\n",
    "dt = 0.4\n",
    "\n",
    "standardization = {\n",
    "    'PEDESTRIAN': {\n",
    "        'position': {\n",
    "            'x': {'mean': 0, 'std': 1},\n",
    "            'y': {'mean': 0, 'std': 1}\n",
    "        },\n",
    "        'velocity': {\n",
    "            'x': {'mean': 0, 'std': 2},\n",
    "            'y': {'mean': 0, 'std': 2}\n",
    "        },\n",
    "        'acceleration': {\n",
    "            'x': {'mean': 0, 'std': 1},\n",
    "            'y': {'mean': 0, 'std': 1}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def maybe_makedirs(path_to_create):\n",
    "    \"\"\"\n",
    "    This function will create a directory, unless it exists already,\n",
    "    at which point the function will return.\n",
    "    The exception handling is necessary as it prevents a race condition\n",
    "    from occurring.\n",
    "    Inputs:\n",
    "        path_to_create - A string path to a directory you'd like created.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path_to_create)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path_to_create):\n",
    "            raise\n",
    "\n",
    "def augment_scene(scene, angle):\n",
    "    \"\"\"\n",
    "    Data augmentation function for scene (rotation). Returns Scene object with augmented data.\n",
    "    \"\"\"\n",
    "    def rotate_pc(pc, alpha):\n",
    "        M = np.array([[np.cos(alpha), -np.sin(alpha)],\n",
    "                      [np.sin(alpha), np.cos(alpha)]])\n",
    "        return M @ pc\n",
    "\n",
    "    data_columns = pd.MultiIndex.from_product([['position', 'velocity', 'acceleration'], ['x', 'y']])\n",
    "\n",
    "    scene_aug = Scene(timesteps=scene.timesteps, dt=scene.dt, name=scene.name)\n",
    "\n",
    "    alpha = angle * np.pi / 180\n",
    "\n",
    "    for node in scene.nodes:\n",
    "        x = node.data.position.x.copy()\n",
    "        y = node.data.position.y.copy()\n",
    "\n",
    "        x, y = rotate_pc(np.array([x, y]), alpha)\n",
    "\n",
    "        vx = derivative_of(x, scene.dt)\n",
    "        vy = derivative_of(y, scene.dt)\n",
    "        ax = derivative_of(vx, scene.dt)\n",
    "        ay = derivative_of(vy, scene.dt)\n",
    "\n",
    "        data_dict = {('position', 'x'): x,\n",
    "                     ('position', 'y'): y,\n",
    "                     ('velocity', 'x'): vx,\n",
    "                     ('velocity', 'y'): vy,\n",
    "                     ('acceleration', 'x'): ax,\n",
    "                     ('acceleration', 'y'): ay}\n",
    "\n",
    "        node_data = pd.DataFrame(data_dict, columns=data_columns)\n",
    "\n",
    "        # Create node and add it to the scene\n",
    "        node = Node(node_type=node.type, node_id=node.id, data=node_data, first_timestep=node.first_timestep)\n",
    "\n",
    "        scene_aug.nodes.append(node)\n",
    "    return scene_aug\n",
    "\n",
    "\n",
    "def augment(scene):\n",
    "    \"\"\"\n",
    "    Executes data augmentation.\n",
    "    \"\"\"\n",
    "    scene_aug = np.random.choice(scene.augmented)\n",
    "    scene_aug.temporal_scene_graph = scene.temporal_scene_graph\n",
    "    return scene_aug\n",
    "\n",
    "def swap_columns(df, col1, col2):\n",
    "    col_list = list(df.columns)\n",
    "    x, y = col_list.index(col1), col_list.index(col2)\n",
    "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
    "    df = df[col_list]\n",
    "    return df\n",
    "\n",
    "def fix_for_assert(df):\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "nl = 0\n",
    "l = 0\n",
    "\n",
    "data_folder_name = 'processed_data_noise'\n",
    "\n",
    "maybe_makedirs(data_folder_name)\n",
    "data_columns = pd.MultiIndex.from_product([['position', 'velocity', 'acceleration'], ['x', 'y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colpevoli_train = []\n",
    "colpevoli_test = []\n",
    "\n",
    "for data_class in [\"train\", \"test\"]:\n",
    "    raw_path = \"raw_data/stanford/longterm\"\n",
    "    out_path = \"processed_data_noise\"\n",
    "    data_path = os.path.join(raw_path, f\"{data_class}_longterm.pkl\")\n",
    "    print(f\"Processing SDD {data_class}\")\n",
    "    data_out_path = os.path.join(out_path, f\"sdd_{data_class}.pkl\")\n",
    "    df = pickle.load(open(data_path, \"rb\"))\n",
    "    df = swap_columns(df, 'trackId', 'frame')\n",
    "    env = Environment(node_type_list=['PEDESTRIAN'], standardization=standardization)\n",
    "    attention_radius = dict()\n",
    "    attention_radius[(env.NodeType.PEDESTRIAN, env.NodeType.PEDESTRIAN)] = 3.0\n",
    "    env.attention_radius = attention_radius\n",
    "\n",
    "    scenes = []\n",
    "\n",
    "    group = df.groupby(\"sceneId\")\n",
    "\n",
    "    for scene, data in group:\n",
    "        data['frame'] = pd.to_numeric(data['frame'], downcast='integer')\n",
    "        data['trackId'] = pd.to_numeric(data['trackId'], downcast='integer')\n",
    "\n",
    "        data['frame'] = data['frame'] // 30\n",
    "\n",
    "        data['frame'] -= data['frame'].min()\n",
    "\n",
    "        data['node_type'] = 'PEDESTRIAN'\n",
    "        data['node_id'] = data['trackId'].astype(str)\n",
    "\n",
    "        # apply data scale as same as PECnet\n",
    "        data['x'] = data['x']/50\n",
    "        data['y'] = data['y']/50\n",
    "\n",
    "        # Mean Position\n",
    "        data['x'] = data['x'] - data['x'].mean()\n",
    "        data['y'] = data['y'] - data['y'].mean()\n",
    "\n",
    "        max_timesteps = data['frame'].max()\n",
    "\n",
    "        if len(data) > 0:\n",
    "            scene = Scene(timesteps=max_timesteps+1, dt=dt, name=\"sdd_\" + data_class, aug_func=augment if data_class == 'train' else None)\n",
    "            n=0\n",
    "            # print(pd.unique(data['node_id']))\n",
    "            for node_id in pd.unique(data['node_id']):\n",
    "                nodes_df = data[data['node_id'] == node_id]\n",
    "                for meta_id in pd.unique(nodes_df['metaId']):\n",
    "                    node_df = nodes_df[nodes_df['metaId'] == meta_id]\n",
    "                    # need to find a way to separate nodes with same id but not contiguous track\n",
    "                    if len(node_df) > 1:\n",
    "                        # if not np.all(np.diff(node_df['frame'])==1):\n",
    "                        #     if data_class == \"train\":\n",
    "                        #         node_df.to_csv('AAA/train_'+node_id+'.csv', sep='\\t')\n",
    "                        #     else:\n",
    "                        #         node_df.to_csv('AAA/test_'+node_id+'.csv', sep='\\t')\n",
    "\n",
    "                        \n",
    "                        assert np.all(np.diff(node_df['frame']) == 1)                         \n",
    "                        node_values = node_df[['x', 'y']].values\n",
    "\n",
    "                        if node_values.shape[0] < 2:\n",
    "                            continue\n",
    "\n",
    "                        new_first_idx = node_df['frame'].iloc[0]\n",
    "\n",
    "                        x = node_values[:, 0]\n",
    "                        y = node_values[:, 1]\n",
    "                        vx = derivative_of(x, scene.dt)\n",
    "                        vy = derivative_of(y, scene.dt)\n",
    "                        ax = derivative_of(vx, scene.dt)\n",
    "                        ay = derivative_of(vy, scene.dt)\n",
    "\n",
    "                        data_dict = {('position', 'x'): x,\n",
    "                                    ('position', 'y'): y,\n",
    "                                    ('velocity', 'x'): vx,\n",
    "                                    ('velocity', 'y'): vy,\n",
    "                                    ('acceleration', 'x'): ax,\n",
    "                                    ('acceleration', 'y'): ay}\n",
    "\n",
    "                        node_data = pd.DataFrame(data_dict, columns=data_columns)\n",
    "                        node = Node(node_type=env.NodeType.PEDESTRIAN, node_id=node_id, data=node_data)\n",
    "                        node.first_timestep = new_first_idx\n",
    "\n",
    "                        scene.nodes.append(node)\n",
    "            if data_class == 'train':\n",
    "                scene.augmented = list()\n",
    "                angles = np.arange(0, 360, 15) if data_class == 'train' else [0]\n",
    "                for angle in angles:\n",
    "                    scene.augmented.append(augment_scene(scene, angle))\n",
    "\n",
    "            print(scene)\n",
    "            scenes.append(scene)\n",
    "    env.scenes = scenes\n",
    "\n",
    "    if len(scenes) > 0:\n",
    "        with open(data_out_path, 'wb') as f:\n",
    "            #pdb.set_trace()\n",
    "            dill.dump(env, f, protocol=dill.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SDD train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>trackId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>sceneId</th>\n",
       "      <th>metaId</th>\n",
       "      <th>node_type</th>\n",
       "      <th>node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2.205903</td>\n",
       "      <td>2.980309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2.365903</td>\n",
       "      <td>2.980309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.525903</td>\n",
       "      <td>2.980309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2.675903</td>\n",
       "      <td>2.980309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>2.835903</td>\n",
       "      <td>3.000309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2.995903</td>\n",
       "      <td>3.000309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>3.155903</td>\n",
       "      <td>3.000309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>3.275903</td>\n",
       "      <td>3.000309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>3.435903</td>\n",
       "      <td>3.000309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>3.515903</td>\n",
       "      <td>3.050309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>3.515903</td>\n",
       "      <td>3.050309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>3.545903</td>\n",
       "      <td>3.050309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>3.545903</td>\n",
       "      <td>3.050309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>3.585903</td>\n",
       "      <td>3.050309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>3.625903</td>\n",
       "      <td>3.050309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>3.625903</td>\n",
       "      <td>3.050309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>3.665903</td>\n",
       "      <td>3.050309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "      <td>3.665903</td>\n",
       "      <td>2.960309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>3.665903</td>\n",
       "      <td>2.920309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>3.665903</td>\n",
       "      <td>2.820309</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame  trackId         x         y      sceneId  metaId   node_type  \\\n",
       "0       0      100  2.205903  2.980309  bookstore_0       0  PEDESTRIAN   \n",
       "1       1      100  2.365903  2.980309  bookstore_0       0  PEDESTRIAN   \n",
       "2       2      100  2.525903  2.980309  bookstore_0       0  PEDESTRIAN   \n",
       "3       3      100  2.675903  2.980309  bookstore_0       0  PEDESTRIAN   \n",
       "4       4      100  2.835903  3.000309  bookstore_0       0  PEDESTRIAN   \n",
       "5       5      100  2.995903  3.000309  bookstore_0       0  PEDESTRIAN   \n",
       "6       6      100  3.155903  3.000309  bookstore_0       0  PEDESTRIAN   \n",
       "7       7      100  3.275903  3.000309  bookstore_0       0  PEDESTRIAN   \n",
       "8       8      100  3.435903  3.000309  bookstore_0       0  PEDESTRIAN   \n",
       "9       9      100  3.515903  3.050309  bookstore_0       0  PEDESTRIAN   \n",
       "10     10      100  3.515903  3.050309  bookstore_0       0  PEDESTRIAN   \n",
       "11     11      100  3.545903  3.050309  bookstore_0       0  PEDESTRIAN   \n",
       "12     12      100  3.545903  3.050309  bookstore_0       0  PEDESTRIAN   \n",
       "13     13      100  3.585903  3.050309  bookstore_0       0  PEDESTRIAN   \n",
       "14     14      100  3.625903  3.050309  bookstore_0       0  PEDESTRIAN   \n",
       "15     15      100  3.625903  3.050309  bookstore_0       0  PEDESTRIAN   \n",
       "16     16      100  3.665903  3.050309  bookstore_0       0  PEDESTRIAN   \n",
       "17     17      100  3.665903  2.960309  bookstore_0       0  PEDESTRIAN   \n",
       "18     18      100  3.665903  2.920309  bookstore_0       0  PEDESTRIAN   \n",
       "19     19      100  3.665903  2.820309  bookstore_0       0  PEDESTRIAN   \n",
       "\n",
       "   node_id  \n",
       "0      100  \n",
       "1      100  \n",
       "2      100  \n",
       "3      100  \n",
       "4      100  \n",
       "5      100  \n",
       "6      100  \n",
       "7      100  \n",
       "8      100  \n",
       "9      100  \n",
       "10     100  \n",
       "11     100  \n",
       "12     100  \n",
       "13     100  \n",
       "14     100  \n",
       "15     100  \n",
       "16     100  \n",
       "17     100  \n",
       "18     100  \n",
       "19     100  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data_class in [\"train\", \"test\"]:\n",
    "    raw_path = \"raw_data/stanford\"\n",
    "    out_path = \"processed_data_noise\"\n",
    "    data_path = os.path.join(raw_path, f\"{data_class}_trajnet.pkl\")\n",
    "    print(f\"Processing SDD {data_class}\")\n",
    "    data_out_path = os.path.join(out_path, f\"sdd_{data_class}.pkl\")\n",
    "    df = pickle.load(open(data_path, \"rb\"))\n",
    "    env = Environment(node_type_list=['PEDESTRIAN'], standardization=standardization)\n",
    "    attention_radius = dict()\n",
    "    attention_radius[(env.NodeType.PEDESTRIAN, env.NodeType.PEDESTRIAN)] = 3.0\n",
    "    env.attention_radius = attention_radius\n",
    "\n",
    "    scenes = []\n",
    "\n",
    "    group = df.groupby(\"sceneId\")\n",
    "\n",
    "    for scene, data in group:\n",
    "        data['frame'] = pd.to_numeric(data['frame'], downcast='integer')\n",
    "        data['trackId'] = pd.to_numeric(data['trackId'], downcast='integer')\n",
    "\n",
    "        data['frame'] = data['frame'] // 12\n",
    "\n",
    "        data['frame'] -= data['frame'].min()\n",
    "\n",
    "        data['node_type'] = 'PEDESTRIAN'\n",
    "        data['node_id'] = data['trackId'].astype(str)\n",
    "\n",
    "        # apply data scale as same as PECnet\n",
    "        data['x'] = data['x']/50\n",
    "        data['y'] = data['y']/50\n",
    "\n",
    "        # Mean Position\n",
    "        data['x'] = data['x'] - data['x'].mean()\n",
    "        data['y'] = data['y'] - data['y'].mean()\n",
    "\n",
    "        max_timesteps = data['frame'].max()\n",
    "\n",
    "        if len(data) > 0:\n",
    "\n",
    "            scene = Scene(timesteps=max_timesteps+1, dt=dt, name=\"sdd_\" + data_class, aug_func=augment if data_class == 'train' else None)\n",
    "            n=0\n",
    "            for node_id in pd.unique(data['node_id']):\n",
    "\n",
    "                node_df = data[data['node_id'] == node_id]\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "node_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SDD train\n",
      "Processing SDD test\n"
     ]
    }
   ],
   "source": [
    "for data_class in [\"train\", \"test\"]:\n",
    "    raw_path = \"raw_data/stanford/longterm\"\n",
    "    out_path = \"processed_data_noise\"\n",
    "    data_path = os.path.join(raw_path, f\"{data_class}_longterm.pkl\")\n",
    "    print(f\"Processing SDD {data_class}\")\n",
    "    data_out_path = os.path.join(out_path, f\"sdd_{data_class}.pkl\")\n",
    "    df = pickle.load(open(data_path, \"rb\"))\n",
    "    df = swap_columns(df, 'trackId', 'frame')\n",
    "    env = Environment(node_type_list=['PEDESTRIAN'], standardization=standardization)\n",
    "    attention_radius = dict()\n",
    "    attention_radius[(env.NodeType.PEDESTRIAN, env.NodeType.PEDESTRIAN)] = 3.0\n",
    "    env.attention_radius = attention_radius\n",
    "\n",
    "    scenes = []\n",
    "\n",
    "    group = df.groupby(\"sceneId\")\n",
    "\n",
    "    for scene, data in group:\n",
    "        data['frame'] = pd.to_numeric(data['frame'], downcast='integer')\n",
    "        data['trackId'] = pd.to_numeric(data['trackId'], downcast='integer')\n",
    "\n",
    "        data['frame'] = data['frame'] // 30\n",
    "\n",
    "        data['frame'] -= data['frame'].min()\n",
    "\n",
    "        data['node_type'] = 'PEDESTRIAN'\n",
    "        data['node_id'] = data['trackId'].astype(str)\n",
    "\n",
    "        # apply data scale as same as PECnet\n",
    "        data['x'] = data['x']/50\n",
    "        data['y'] = data['y']/50\n",
    "\n",
    "        # Mean Position\n",
    "        data['x'] = data['x'] - data['x'].mean()\n",
    "        data['y'] = data['y'] - data['y'].mean()\n",
    "\n",
    "        max_timesteps = data['frame'].max()\n",
    "\n",
    "        if len(data) > 0:\n",
    "            scene = Scene(timesteps=max_timesteps+1, dt=dt, name=\"sdd_\" + data_class, aug_func=augment if data_class == 'train' else None)\n",
    "            n=0\n",
    "            # print(pd.unique(data['node_id']))\n",
    "            for node_id in pd.unique(data['node_id']):\n",
    "                nodes_df = data[data['node_id'] == node_id]\n",
    "                for meta_id in pd.unique(nodes_df['metaId']):\n",
    "                    node_df = nodes_df[nodes_df['metaId'] == meta_id]\n",
    "                    node_df.to_csv('AAA/longterm/'+data_class+'nodeid'+str(node_id)+'_metaid'+str(meta_id)+'.csv', sep='\\t')\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SDD train\n",
      "Processing SDD test\n"
     ]
    }
   ],
   "source": [
    "for data_class in [\"train\", \"test\"]:\n",
    "    raw_path = \"raw_data/stanford\"\n",
    "    out_path = \"processed_data_noise\"\n",
    "    data_path = os.path.join(raw_path, f\"{data_class}_trajnet.pkl\")\n",
    "    print(f\"Processing SDD {data_class}\")\n",
    "    data_out_path = os.path.join(out_path, f\"sdd_{data_class}.pkl\")\n",
    "    df = pickle.load(open(data_path, \"rb\"))\n",
    "    env = Environment(node_type_list=['PEDESTRIAN'], standardization=standardization)\n",
    "    attention_radius = dict()\n",
    "    attention_radius[(env.NodeType.PEDESTRIAN, env.NodeType.PEDESTRIAN)] = 3.0\n",
    "    env.attention_radius = attention_radius\n",
    "\n",
    "    scenes = []\n",
    "\n",
    "    group = df.groupby(\"sceneId\")\n",
    "\n",
    "    for scene, data in group:\n",
    "        data['frame'] = pd.to_numeric(data['frame'], downcast='integer')\n",
    "        data['trackId'] = pd.to_numeric(data['trackId'], downcast='integer')\n",
    "\n",
    "        data['frame'] = data['frame'] // 12\n",
    "\n",
    "        data['frame'] -= data['frame'].min()\n",
    "\n",
    "        data['node_type'] = 'PEDESTRIAN'\n",
    "        data['node_id'] = data['trackId'].astype(str)\n",
    "\n",
    "        # apply data scale as same as PECnet\n",
    "        data['x'] = data['x']/50\n",
    "        data['y'] = data['y']/50\n",
    "\n",
    "        # Mean Position\n",
    "        data['x'] = data['x'] - data['x'].mean()\n",
    "        data['y'] = data['y'] - data['y'].mean()\n",
    "\n",
    "        max_timesteps = data['frame'].max()\n",
    "\n",
    "        if len(data) > 0:\n",
    "\n",
    "            scene = Scene(timesteps=max_timesteps+1, dt=dt, name=\"sdd_\" + data_class, aug_func=augment if data_class == 'train' else None)\n",
    "            n=0\n",
    "            for node_id in pd.unique(data['node_id']):\n",
    "\n",
    "                node_df = data[data['node_id'] == node_id]\n",
    "                node_df.to_csv('AAA/shortterm/'+data_class+'nodeid'+str(node_id)+'.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
